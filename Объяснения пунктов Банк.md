# 1 пункт

```
Настроил асинхронную обработку email-рассылок, уведомлений и длительных операций.
Добавил автоматические повторы задач, логирование. В результате API стал быстрее отвечать на запросы пользователей, улучшена надёжность рассылок и снижено количество жалоб от сотрудников на задержки.
```


Мы начали сталкивались с проблемой: при создании заявок система отправляла множество email-уведомлений, что сильно замедляло работу API. Чтобы решить это,  было принято решение внедрить асинхронную обработку через celery. Я вынес логику отправки писем в отдельные задачи, добавил автоматические повторы в случае ошибок и настроил логирование для отслеживания успешных и неуспешных попыток. Это позволило освободить основной поток API и значительно ускорить отклик.

## Более подробное объяснение:

### **Как это реализуется**

- Используется **Celery** для выполнения фоновых задач.
- Задачи (например, отправка email) выносятся в Celery-таски и вызываются через `delay()` или `apply_async()`.
- Для повторных попыток используется параметр `autoretry_for` в декораторе `@task`, либо ручное управление retries внутри таска.
- Логирование делается с помощью стандартного модуля `logging`.

### Как ты реализовал автоматические повторы задач?

Использовал механизм автоповторов в Celery — параметр `autoretry_for`. Также можно добавить лимит повторов через `retry_kwargs`. В случае ошибок задача переходит в очередь и выполняется повторно.

---

# 2 пункт

```
Перевёл тяжелые операции по выгрузке данных в асинхронный режим через Celery, тем самым снизил потребление RAM на 24% и повысил стабильность работы сервиса при пиковых нагрузках.
```

После январских праздников вылезла на поверхность неприятная ситуация - сервис начал ловить OOM (out of memory), когда запрашивались данные по работе в праздничные дни, тк запрашивались данные по большому количеству сотрудников сразу. С помощью мониторинга (Htop, grafana+prometheus)

Я решил перевести эти тяжёлые операции в асинхронный режим через Celery. То есть вместо того, чтобы держать пользователя в ожидании, я создавал фоновую задачу, которая обрабатывала данные в отдельном процессе и формировала отчет.

Пользователь получал отчет на почту в формате excel. Такой подход значительно снизил нагрузку на RAM — примерно на 24%, и повысил общую стабильность сервиса при пиковых нагрузках.

В итоге мы смогли избежать простоев и сделать работу с отчётами удобнее и безопаснее.


### Почему выгрузка данных в синхронном режиме влияет на RAM?

Потому что при обработке больших объёмов данных внутри HTTP-запроса — всё выполняется в основном потоке, память не освобождается до завершения. Это может вызвать OOM (out of memory), особенно если таких запросов несколько одновременно.

---

# 3 пункт

```
Покрыл кодовую базу unit и интеграционными тестами до 80% для ключевых процессов: создание заявок, расчёт отпусков, изменение ставок и проверка доступов, что в свою очередь ускорило выход новых фич в production и повысило доверие со стороны QA и продуктовой команды.
```

## Ответ в формальном виде

Раньше у нас были проблемы с регрессиями — после новых релизов могли сломаться старые фичи, особенно связанные с расчётами отпусков и доступами. Чтобы повысить стабильность, я взял инициативу и начал активно писать unit и интеграционные тесты.

Мы покрыли ключевые процессы: создание заявок, расчёт отпусков, изменение ставок и проверку прав доступа. Для замера покрытия использовали `coverage.py`, а тесты писали на `pytest`.

Со временем QA стала меньше находить багов на этапе тестирования, и мы начали быстрее выпускать новые фичи, потому что были уверены в том, что ничего не сломаем.

---

### Чем отличаются unit и интеграционные тесты?

Unit-тесты проверяют отдельные функции или классы, интеграционные — взаимодействие между компонентами (например, API + БД).

### Как измерялось покрытие?

С помощью `coverage.py`: запуск тестов с `coverage run -m pytest`, затем вывод отчёта через `coverage report`.

### Как тестировать внешние сервисы (например, RabbitMQ)?

Можно использовать моки (`unittest.mock`) или тестовые контейнеры Docker, чтобы эмулировать внешние зависимости.


---

# 4 пункт

```
Использовал Alembic для управления миграциями PostgreSQL. Писал обратимые миграции, обеспечивая совместимость с предыдущими версиями сервиса. Это позволило избежать потерь данных при сбоях и снизило риски при деплоях.
```

## **Как это реализуется**

- Миграции создаются через `alembic revision --autogenerate`.
- Все миграции были обратимыми — имели метод `downgrade()`.

### Как обрабатывать данные при миграции?

Если нужно перенести данные, то пишутся специальные миграции с обработкой старых записей. Например, заполнение нового поля значениями из старого.

### Как тестировать миграции?

Запускать их в тестовой среде, проверять, что они применяются и откатываются без ошибок. Можно использовать тестовые фикстуры и отдельную БД.


---

# 5 пункт

```
Участвовал в код-ревью, что повлияло на повышение читаемости и поддерживаемости кода.
```


> В команде из 8 человек важно было сохранять качество кода и единые стандарты. Я активно участвовал в код-ревью, где проверял не только функциональность, но и читаемость, соответствие PEP8, наличие документации и тестов.
> 
> Часто я предлагал рефакторинг, указывал на возможные баги и делился лучшими практиками. Это помогло сделать кодовую базу более однородной и понятной для всех разработчиков.
> 
> Также это научило меня лучше объяснять свою точку зрения и принимать конструктивную критику от коллег.


### Какие моменты ты обычно проверяешь в код-ревью?

- Соответствие PEP8 и внутренним стандартам.
- Наличие документации и комментариев к сложным частям.
- Тесты: есть ли покрытие новой фичи?

### Как ты реагируешь, если разработчик не принимает твои замечания?

Обсуждаю в комментариях, привожу примеры, почему так лучше. Если нет согласия, обращаемся к техлиду или решаем на встрече команды.


---

# Доп. вопросы

#### Как собирались метрики через Prometheus?

Использовали middleware для FastAPI, которая собирала время ответа, количество запросов и ошибок. Данные забирал Prometheus, отображались в Grafana.
